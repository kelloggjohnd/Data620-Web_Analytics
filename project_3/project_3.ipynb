{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "oriental-reception",
   "metadata": {},
   "source": [
    "# Project 3 - Text Mining\n",
    "\n",
    "Predict Name-Gender Labels with NLTK \"names\" data.\n",
    "\n",
    "---\n",
    "\n",
    "Jeff Shamp, John Kellogg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "promising-landing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/Users/jeffshamp/.conda/envs/sps620/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#nltk.download('names')\n",
    "from nltk.corpus import names\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-aaron",
   "metadata": {},
   "source": [
    "## Load Data - Extract Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-answer",
   "metadata": {},
   "source": [
    "We will first load up the data, organize it into a dataframe and extract some features like min, max, and average length of name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "considerable-canyon",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_dict = {'name':names.words()}\n",
    "names_df = pd.DataFrame(data= names_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "opposed-copying",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_names(row):\n",
    "    if row in names.words('female.txt'):\n",
    "        return \"female\"\n",
    "    if row in names.words('male.txt'):\n",
    "        return \"male\"\n",
    "    else: return -1\n",
    "    \n",
    "def get_last_letter(row):\n",
    "    return row[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "champion-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not the most efficient use of python or lists or encoders, but it works\n",
    "names_df['label'] = names_df.name.apply(lambda x: label_names(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "environmental-numbers",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_df['last_letter'] = names_df.name.apply(lambda x: get_last_letter(x))\n",
    "names_df = names_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "applied-justice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min length name: 2\n",
      "Average length name: 6.03285498489426\n",
      "Median length name: 6.0\n",
      "Max length name: 15\n"
     ]
    }
   ],
   "source": [
    "print(f\"Min length name: {names_df.name.apply(len).min()}\",\n",
    "      f\"Average length name: {names_df.name.apply(len).mean()}\",\n",
    "      f\"Median length name: {names_df.name.apply(len).median()}\",\n",
    "      f\"Max length name: {names_df.name.apply(len).max()}\",\n",
    "      sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-atmosphere",
   "metadata": {},
   "source": [
    "## Base Line Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-vanilla",
   "metadata": {},
   "source": [
    "The book uses a Naive Bayes classifer for determining name-gender congruence using a simple last letter scheme. The model shown in the book achieved a 0.782 accuracy. This is what we intend to beat. \n",
    "\n",
    "We will leverage the fact that there is a diversity of name length to create character n-grams of the names and assign count scores to those character n-grams. Above we see that the minimum length name is 2 characters and maximum is 15 characters. We will build n-grams to count from 0 - 15. After several tests we found that this combination is likely to be the best for model accuaracy and precision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "wound-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_vectorizer = CountVectorizer(analyzer='char', ngram_range=(0, 16))\n",
    "X = char_vectorizer.fit_transform(names_df.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "rental-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse to sparse matrix\n",
    "X = X.tocsc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "falling-private",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dev = X[500:]\n",
    "test = X[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "soviet-wyoming",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = \\\n",
    "train_test_split(train_dev,\n",
    "                  names_df['label'][500:],\n",
    "                  test_size=0.07,\n",
    "                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "independent-refund",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_model = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "square-conservation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.88      0.93      0.90       359\n",
      "        male       0.82      0.72      0.76       163\n",
      "\n",
      "    accuracy                           0.86       522\n",
      "   macro avg       0.85      0.82      0.83       522\n",
      "weighted avg       0.86      0.86      0.86       522\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, naive_model.predict(X_dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "patent-daisy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[333  26]\n",
      " [ 46 117]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_dev, naive_model.predict(X_dev)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-breeding",
   "metadata": {},
   "source": [
    "## Initial Results\n",
    "\n",
    "Using a similar (or same family of classifiers) model we can achieve much higher accuaracy on predicting name-gender using character n-grams than what was used in the book. Let's now push it further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "motivated-liberty",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC(gamma='scale').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "proper-amazon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.85      0.95      0.90       359\n",
      "        male       0.86      0.64      0.74       163\n",
      "\n",
      "    accuracy                           0.86       522\n",
      "   macro avg       0.86      0.80      0.82       522\n",
      "weighted avg       0.86      0.86      0.85       522\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, svm_model.predict(X_dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "unknown-forum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[342  17]\n",
      " [ 58 105]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_dev, svm_model.predict(X_dev)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-thumbnail",
   "metadata": {},
   "source": [
    "SVM is no better than the base line model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-image",
   "metadata": {},
   "source": [
    "#### Logistic Regression is the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "negative-nudist",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model = LogisticRegression(max_iter=3000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "blank-witness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.91      0.96      0.93       359\n",
      "        male       0.90      0.79      0.84       163\n",
      "\n",
      "    accuracy                           0.90       522\n",
      "   macro avg       0.90      0.87      0.88       522\n",
      "weighted avg       0.90      0.90      0.90       522\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, logit_model.predict(X_dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "killing-message",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[344  15]\n",
      " [ 35 128]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_dev, logit_model.predict(X_dev)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-spectacular",
   "metadata": {},
   "source": [
    "The Logit also minimizes False Negtives/False Positive ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "occupied-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmb_model = GradientBoostingClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "received-journey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.81      0.96      0.88       359\n",
      "        male       0.84      0.51      0.63       163\n",
      "\n",
      "    accuracy                           0.82       522\n",
      "   macro avg       0.82      0.73      0.76       522\n",
      "weighted avg       0.82      0.82      0.80       522\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, gmb_model.predict(X_dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "improved-alert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[343  16]\n",
      " [ 80  83]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_dev, gmb_model.predict(X_dev)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-private",
   "metadata": {},
   "source": [
    "## Development Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-trademark",
   "metadata": {},
   "source": [
    "We see that the best model is the most simple. The logistic regression model significantly better than the base line model. Whereas the, more complex, and generally superior Tree Boosted model was worse than the base model. If constrained to a Navie Bayesian model only, our NB model trained on character n-grams demonstrated better results (86% accuracy) as compared to the base model (78%). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-michigan",
   "metadata": {},
   "source": [
    "## Test Set Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-subject",
   "metadata": {},
   "source": [
    "Fit the best development model to the entire training set and evaluate on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "conceptual-setting",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = LogisticRegression(max_iter=3000).fit(train_dev, names_df.label[500:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "retired-freeware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.89      0.94      0.91       341\n",
      "        male       0.86      0.74      0.79       159\n",
      "\n",
      "    accuracy                           0.88       500\n",
      "   macro avg       0.87      0.84      0.85       500\n",
      "weighted avg       0.88      0.88      0.88       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(names_df.label[:500], final_model.predict(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "arranged-characterization",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[321  20]\n",
      " [ 41 118]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(names_df.label[:500], final_model.predict(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-manchester",
   "metadata": {},
   "source": [
    "Consistent results from the development set. Great!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
