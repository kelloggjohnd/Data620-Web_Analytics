{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "white-aurora",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\x\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\",500)\n",
    "import nltk.corpus\n",
    "random.seed(42)\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-selling",
   "metadata": {},
   "source": [
    "https://www.huffpost.com/entry/obama-is-americas-3rd-gre_b_813868\n",
    "\n",
    "Can we use text mining to predict the speeches of the top Presidential Orators since 1933?\n",
    "What are their commonalities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "simplified-cattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-mattress",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv('data/corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = pd.read_csv('data/presidential_speeches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-offering",
   "metadata": {},
   "source": [
    "Import text from R script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "going-style",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\data620_web\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: 'U' mode is deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "ob=open('data/obama1.txt','rU')\n",
    "raw_o=ob.read()\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "obama = tokenizer.tokenize(raw_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "overhead-worse",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\data620_web\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: 'U' mode is deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "wa=open('data/washington.txt','rU')\n",
    "raw_wa=wa.read()\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "washington = tokenizer.tokenize(raw_wa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-argument",
   "metadata": {},
   "source": [
    "Update the text, remove stop words, lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "korean-nicaragua",
   "metadata": {},
   "outputs": [],
   "source": [
    "obama = [word.lower() for word in obama if word.isalpha()]\n",
    "washington = [word.lower() for word in washington if word.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "authentic-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_without_sw = []\n",
    "for word in obama:\n",
    "    if word not in stop_words:\n",
    "        tokens_without_sw.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sustainable-algebra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transcripts',\n",
       " 'chairman',\n",
       " 'dean',\n",
       " 'great',\n",
       " 'friend',\n",
       " 'dick',\n",
       " 'durbin',\n",
       " 'fellow',\n",
       " 'citizens',\n",
       " 'great',\n",
       " 'nation',\n",
       " 'profound',\n",
       " 'gratitude',\n",
       " 'great',\n",
       " 'humility',\n",
       " 'accept',\n",
       " 'nomination',\n",
       " 'presidency',\n",
       " 'united',\n",
       " 'states',\n",
       " 'let',\n",
       " 'express',\n",
       " 'thanks',\n",
       " 'historic',\n",
       " 'slate',\n",
       " 'candidates',\n",
       " 'accompanied',\n",
       " 'journey',\n",
       " 'especially',\n",
       " 'one',\n",
       " 'traveled',\n",
       " 'farthest',\n",
       " 'champion',\n",
       " 'working',\n",
       " 'americans',\n",
       " 'inspiration',\n",
       " 'daughters',\n",
       " 'hillary',\n",
       " 'rodham',\n",
       " 'clinton',\n",
       " 'president',\n",
       " 'clinton',\n",
       " 'last',\n",
       " 'night',\n",
       " 'made',\n",
       " 'case',\n",
       " 'change',\n",
       " 'make',\n",
       " 'ted',\n",
       " 'kennedy',\n",
       " 'embodies',\n",
       " 'spirit',\n",
       " 'service',\n",
       " 'next',\n",
       " 'vice',\n",
       " 'president',\n",
       " 'united',\n",
       " 'states',\n",
       " 'joe',\n",
       " 'biden',\n",
       " 'thank',\n",
       " 'grateful',\n",
       " 'finish',\n",
       " 'journey',\n",
       " 'one',\n",
       " 'finest',\n",
       " 'statesmen',\n",
       " 'time',\n",
       " 'man',\n",
       " 'ease',\n",
       " 'everyone',\n",
       " 'world',\n",
       " 'leaders',\n",
       " 'conductors',\n",
       " 'amtrak',\n",
       " 'train',\n",
       " 'still',\n",
       " 'takes',\n",
       " 'home',\n",
       " 'every',\n",
       " 'night',\n",
       " 'love',\n",
       " 'life',\n",
       " 'next',\n",
       " 'first',\n",
       " 'lady',\n",
       " 'michelle',\n",
       " 'obama',\n",
       " 'sasha',\n",
       " 'malia',\n",
       " 'love',\n",
       " 'much',\n",
       " 'proud',\n",
       " 'four',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'stood',\n",
       " 'told',\n",
       " 'story',\n",
       " 'brief',\n",
       " 'union',\n",
       " 'young',\n",
       " 'man',\n",
       " 'kenya',\n",
       " 'young',\n",
       " 'woman',\n",
       " 'kansas',\n",
       " 'well',\n",
       " 'well',\n",
       " 'known',\n",
       " 'shared',\n",
       " 'belief',\n",
       " 'america',\n",
       " 'son',\n",
       " 'could',\n",
       " 'achieve',\n",
       " 'whatever',\n",
       " 'put',\n",
       " 'mind',\n",
       " 'promise',\n",
       " 'always',\n",
       " 'set',\n",
       " 'country',\n",
       " 'apart',\n",
       " 'hard',\n",
       " 'work',\n",
       " 'sacrifice',\n",
       " 'us',\n",
       " 'pursue',\n",
       " 'individual',\n",
       " 'dreams',\n",
       " 'still',\n",
       " 'come',\n",
       " 'together',\n",
       " 'one',\n",
       " 'american',\n",
       " 'family',\n",
       " 'ensure',\n",
       " 'next',\n",
       " 'generation',\n",
       " 'pursue',\n",
       " 'dreams',\n",
       " 'well',\n",
       " 'stand',\n",
       " 'tonight',\n",
       " 'two',\n",
       " 'hundred',\n",
       " 'thirty',\n",
       " 'two',\n",
       " 'years',\n",
       " 'moment',\n",
       " 'promise',\n",
       " 'jeopardy',\n",
       " 'ordinary',\n",
       " 'men',\n",
       " 'women',\n",
       " 'students',\n",
       " 'soldiers',\n",
       " 'farmers',\n",
       " 'teachers',\n",
       " 'nurses',\n",
       " 'janitors',\n",
       " 'found',\n",
       " 'courage',\n",
       " 'keep',\n",
       " 'alive',\n",
       " 'meet',\n",
       " 'one',\n",
       " 'defining',\n",
       " 'moments',\n",
       " 'moment',\n",
       " 'nation',\n",
       " 'war',\n",
       " 'economy',\n",
       " 'turmoil',\n",
       " 'american',\n",
       " 'promise',\n",
       " 'threatened',\n",
       " 'tonight',\n",
       " 'americans',\n",
       " 'work',\n",
       " 'working',\n",
       " 'harder',\n",
       " 'less',\n",
       " 'lost',\n",
       " 'homes',\n",
       " 'even',\n",
       " 'watching',\n",
       " 'home',\n",
       " 'values',\n",
       " 'plummet',\n",
       " 'cars',\n",
       " 'afford',\n",
       " 'drive',\n",
       " 'credit',\n",
       " 'card',\n",
       " 'bills',\n",
       " 'afford',\n",
       " 'pay',\n",
       " 'tuition',\n",
       " 'beyond',\n",
       " 'reach',\n",
       " 'challenges',\n",
       " 'government',\n",
       " 'making',\n",
       " 'failure',\n",
       " 'respond',\n",
       " 'direct',\n",
       " 'result',\n",
       " 'broken',\n",
       " 'politics',\n",
       " 'washington',\n",
       " 'failed',\n",
       " 'policies',\n",
       " 'george',\n",
       " 'w',\n",
       " 'bush',\n",
       " 'america',\n",
       " 'better',\n",
       " 'last',\n",
       " 'eight',\n",
       " 'years',\n",
       " 'better',\n",
       " 'country',\n",
       " 'country',\n",
       " 'decent',\n",
       " 'one',\n",
       " 'woman',\n",
       " 'ohio',\n",
       " 'brink',\n",
       " 'retirement',\n",
       " 'finds',\n",
       " 'one',\n",
       " 'illness',\n",
       " 'away',\n",
       " 'disaster',\n",
       " 'lifetime',\n",
       " 'hard',\n",
       " 'work',\n",
       " 'country',\n",
       " 'generous',\n",
       " 'one',\n",
       " 'man',\n",
       " 'indiana',\n",
       " 'pack',\n",
       " 'equipment',\n",
       " 'worked',\n",
       " 'twenty',\n",
       " 'years',\n",
       " 'watch',\n",
       " 'shipped',\n",
       " 'china',\n",
       " 'chokes',\n",
       " 'explains',\n",
       " 'felt',\n",
       " 'like',\n",
       " 'failure',\n",
       " 'went',\n",
       " 'home',\n",
       " 'tell',\n",
       " 'family',\n",
       " 'news',\n",
       " 'compassionate',\n",
       " 'government',\n",
       " 'lets',\n",
       " 'veterans',\n",
       " 'sleep',\n",
       " 'streets',\n",
       " 'families',\n",
       " 'slide',\n",
       " 'poverty',\n",
       " 'sits',\n",
       " 'hands',\n",
       " 'major',\n",
       " 'american',\n",
       " 'city',\n",
       " 'drowns',\n",
       " 'eyes',\n",
       " 'tonight',\n",
       " 'say',\n",
       " 'american',\n",
       " 'people',\n",
       " 'democrats',\n",
       " 'republicans',\n",
       " 'independents',\n",
       " 'across',\n",
       " 'great',\n",
       " 'land',\n",
       " 'enough',\n",
       " 'moment',\n",
       " 'election',\n",
       " 'chance',\n",
       " 'keep',\n",
       " 'century',\n",
       " 'american',\n",
       " 'promise',\n",
       " 'alive',\n",
       " 'next',\n",
       " 'week',\n",
       " 'minnesota',\n",
       " 'party',\n",
       " 'brought',\n",
       " 'two',\n",
       " 'terms',\n",
       " 'george',\n",
       " 'bush',\n",
       " 'dick',\n",
       " 'cheney',\n",
       " 'ask',\n",
       " 'country',\n",
       " 'third',\n",
       " 'love',\n",
       " 'country',\n",
       " 'much',\n",
       " 'let',\n",
       " 'next',\n",
       " 'four',\n",
       " 'years',\n",
       " 'look',\n",
       " 'like',\n",
       " 'last',\n",
       " 'eight',\n",
       " 'november',\n",
       " 'must',\n",
       " 'stand',\n",
       " 'say',\n",
       " 'eight',\n",
       " 'enough',\n",
       " 'let',\n",
       " 'doubt',\n",
       " 'republican',\n",
       " 'nominee',\n",
       " 'john',\n",
       " 'mccain',\n",
       " 'worn',\n",
       " 'uniform',\n",
       " 'country',\n",
       " 'bravery',\n",
       " 'distinction',\n",
       " 'owe',\n",
       " 'gratitude',\n",
       " 'respect',\n",
       " 'next',\n",
       " 'week',\n",
       " 'also',\n",
       " 'hear',\n",
       " 'occasions',\n",
       " 'broken',\n",
       " 'party',\n",
       " 'evidence',\n",
       " 'deliver',\n",
       " 'change',\n",
       " 'need',\n",
       " 'record',\n",
       " 'clear',\n",
       " 'john',\n",
       " 'mccain',\n",
       " 'voted',\n",
       " 'george',\n",
       " 'bush',\n",
       " 'ninety',\n",
       " 'percent',\n",
       " 'time',\n",
       " 'senator',\n",
       " 'mccain',\n",
       " 'likes',\n",
       " 'talk',\n",
       " 'judgment',\n",
       " 'really',\n",
       " 'say',\n",
       " 'judgment',\n",
       " 'think',\n",
       " 'george',\n",
       " 'bush',\n",
       " 'right',\n",
       " 'ninety',\n",
       " 'percent',\n",
       " 'time',\n",
       " 'know',\n",
       " 'ready',\n",
       " 'take',\n",
       " 'ten',\n",
       " 'percent',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'truth',\n",
       " 'issue',\n",
       " 'issue',\n",
       " 'would',\n",
       " 'make',\n",
       " 'difference',\n",
       " 'lives',\n",
       " 'health',\n",
       " 'care',\n",
       " 'education',\n",
       " 'economy',\n",
       " 'senator',\n",
       " 'mccain',\n",
       " 'anything',\n",
       " 'independent',\n",
       " 'said',\n",
       " 'economy',\n",
       " 'made',\n",
       " 'great',\n",
       " 'progress',\n",
       " 'president',\n",
       " 'said',\n",
       " 'fundamentals',\n",
       " 'economy',\n",
       " 'strong',\n",
       " 'one',\n",
       " 'chief',\n",
       " 'advisors',\n",
       " 'man',\n",
       " 'wrote',\n",
       " 'economic',\n",
       " 'plan',\n",
       " 'talking',\n",
       " 'anxiety',\n",
       " 'americans',\n",
       " 'feeling',\n",
       " 'said',\n",
       " 'suffering',\n",
       " 'mental',\n",
       " 'recession',\n",
       " 'become',\n",
       " 'quote',\n",
       " 'nation',\n",
       " 'whiners',\n",
       " 'nation',\n",
       " 'whiners',\n",
       " 'tell',\n",
       " 'proud',\n",
       " 'auto',\n",
       " 'workers',\n",
       " 'michigan',\n",
       " 'plant',\n",
       " 'found',\n",
       " 'closing',\n",
       " 'kept',\n",
       " 'showing',\n",
       " 'every',\n",
       " 'day',\n",
       " 'working',\n",
       " 'hard',\n",
       " 'ever',\n",
       " 'knew',\n",
       " 'people',\n",
       " 'counted',\n",
       " 'brakes',\n",
       " 'made',\n",
       " 'tell',\n",
       " 'military',\n",
       " 'families',\n",
       " 'shoulder',\n",
       " 'burdens',\n",
       " 'silently',\n",
       " 'watch',\n",
       " 'loved',\n",
       " 'ones',\n",
       " 'leave',\n",
       " 'third',\n",
       " 'fourth',\n",
       " 'fifth',\n",
       " 'tour',\n",
       " 'duty',\n",
       " 'whiners',\n",
       " 'work',\n",
       " 'hard',\n",
       " 'give',\n",
       " 'back',\n",
       " 'keep',\n",
       " 'going',\n",
       " 'without',\n",
       " 'complaint',\n",
       " 'americans',\n",
       " 'know',\n",
       " 'believe',\n",
       " 'senator',\n",
       " 'mccain',\n",
       " 'care',\n",
       " 'going',\n",
       " 'lives',\n",
       " 'americans',\n",
       " 'think',\n",
       " 'know',\n",
       " 'else',\n",
       " 'would',\n",
       " 'define',\n",
       " 'middle',\n",
       " 'class',\n",
       " 'someone',\n",
       " 'making',\n",
       " 'five',\n",
       " 'million',\n",
       " 'dollars',\n",
       " 'year',\n",
       " 'else',\n",
       " 'could',\n",
       " 'propose',\n",
       " 'hundreds',\n",
       " 'billions',\n",
       " 'tax',\n",
       " 'breaks',\n",
       " 'big',\n",
       " 'corporations',\n",
       " 'oil',\n",
       " 'companies',\n",
       " 'one',\n",
       " 'penny',\n",
       " 'tax',\n",
       " 'relief',\n",
       " 'one',\n",
       " 'hundred',\n",
       " 'million',\n",
       " 'americans',\n",
       " 'else',\n",
       " 'could',\n",
       " 'offer',\n",
       " 'health',\n",
       " 'care',\n",
       " 'plan',\n",
       " 'would',\n",
       " 'actually',\n",
       " 'tax',\n",
       " 'people',\n",
       " 'benefits',\n",
       " 'education',\n",
       " 'plan',\n",
       " 'would',\n",
       " 'nothing',\n",
       " 'help',\n",
       " 'families',\n",
       " 'pay',\n",
       " 'college',\n",
       " 'plan',\n",
       " 'would',\n",
       " 'privatize',\n",
       " 'social',\n",
       " 'security',\n",
       " 'gamble',\n",
       " 'retirement',\n",
       " 'john',\n",
       " 'mccain',\n",
       " 'care',\n",
       " 'john',\n",
       " 'mccain',\n",
       " 'get',\n",
       " 'two',\n",
       " 'decades',\n",
       " 'subscribed',\n",
       " 'old',\n",
       " 'discredited',\n",
       " 'republican',\n",
       " 'philosophy',\n",
       " 'give',\n",
       " 'hope',\n",
       " 'prosperity',\n",
       " 'trickles',\n",
       " 'everyone',\n",
       " 'else',\n",
       " 'washington',\n",
       " 'call',\n",
       " 'ownership',\n",
       " 'society',\n",
       " 'really',\n",
       " 'means',\n",
       " 'work',\n",
       " 'tough',\n",
       " 'luck',\n",
       " 'health',\n",
       " 'care',\n",
       " 'market',\n",
       " 'fix',\n",
       " 'born',\n",
       " 'poverty',\n",
       " 'pull',\n",
       " 'bootstraps',\n",
       " 'even',\n",
       " 'boots',\n",
       " 'well',\n",
       " 'time',\n",
       " 'failure',\n",
       " 'time',\n",
       " 'us',\n",
       " 'change',\n",
       " 'america',\n",
       " 'see',\n",
       " 'democrats',\n",
       " 'different',\n",
       " 'measure',\n",
       " 'constitutes',\n",
       " 'progress',\n",
       " 'country',\n",
       " 'measure',\n",
       " 'progress',\n",
       " 'many',\n",
       " 'people',\n",
       " 'find',\n",
       " 'job',\n",
       " 'pays',\n",
       " 'mortgage',\n",
       " 'whether',\n",
       " 'put',\n",
       " 'little',\n",
       " 'extra',\n",
       " 'money',\n",
       " 'away',\n",
       " 'end',\n",
       " 'month',\n",
       " 'someday',\n",
       " 'watch',\n",
       " 'child',\n",
       " 'receive',\n",
       " 'college',\n",
       " 'diploma',\n",
       " 'measure',\n",
       " 'progress',\n",
       " 'million',\n",
       " 'new',\n",
       " 'jobs',\n",
       " 'created',\n",
       " 'bill',\n",
       " 'clinton',\n",
       " 'president',\n",
       " 'average',\n",
       " 'american',\n",
       " 'family',\n",
       " 'saw',\n",
       " 'income',\n",
       " 'go',\n",
       " 'instead',\n",
       " 'like',\n",
       " 'george',\n",
       " 'bush',\n",
       " 'measure',\n",
       " 'strength',\n",
       " 'economy',\n",
       " 'number',\n",
       " 'billionaires',\n",
       " 'profits',\n",
       " 'fortune',\n",
       " 'whether',\n",
       " 'someone',\n",
       " 'good',\n",
       " 'idea',\n",
       " 'take',\n",
       " 'risk',\n",
       " 'start',\n",
       " 'new',\n",
       " 'business',\n",
       " 'whether',\n",
       " 'waitress',\n",
       " 'lives',\n",
       " 'tips',\n",
       " 'take',\n",
       " 'day',\n",
       " 'look',\n",
       " 'sick',\n",
       " 'kid',\n",
       " 'without',\n",
       " 'losing',\n",
       " 'job',\n",
       " 'economy',\n",
       " 'honors',\n",
       " 'dignity',\n",
       " 'work',\n",
       " 'fundamentals',\n",
       " 'use',\n",
       " 'measure',\n",
       " 'economic',\n",
       " 'strength',\n",
       " 'whether',\n",
       " 'living',\n",
       " 'fundamental',\n",
       " 'promise',\n",
       " 'made',\n",
       " 'country',\n",
       " 'great',\n",
       " 'promise',\n",
       " 'reason',\n",
       " 'standing',\n",
       " 'tonight',\n",
       " 'faces',\n",
       " 'young',\n",
       " 'veterans',\n",
       " 'come',\n",
       " 'back',\n",
       " 'iraq',\n",
       " 'afghanistan',\n",
       " 'see',\n",
       " 'grandfather',\n",
       " 'signed',\n",
       " 'pearl',\n",
       " 'harbor',\n",
       " 'marched',\n",
       " 'patton',\n",
       " 'army',\n",
       " 'rewarded',\n",
       " 'grateful',\n",
       " 'nation',\n",
       " 'chance',\n",
       " 'go',\n",
       " 'college',\n",
       " 'gi',\n",
       " 'bill',\n",
       " 'face',\n",
       " 'young',\n",
       " 'student',\n",
       " 'sleeps',\n",
       " 'three',\n",
       " 'hours',\n",
       " 'working',\n",
       " 'night',\n",
       " 'shift',\n",
       " 'think',\n",
       " 'mom',\n",
       " 'raised',\n",
       " 'sister',\n",
       " 'worked',\n",
       " 'earned',\n",
       " 'degree',\n",
       " 'turned',\n",
       " 'food',\n",
       " 'stamps',\n",
       " 'still',\n",
       " 'able',\n",
       " 'send',\n",
       " 'us',\n",
       " 'best',\n",
       " 'schools',\n",
       " 'country',\n",
       " 'help',\n",
       " 'student',\n",
       " 'loans',\n",
       " 'scholarships',\n",
       " 'listen',\n",
       " 'another',\n",
       " 'worker',\n",
       " 'tell',\n",
       " 'factory',\n",
       " 'shut',\n",
       " 'remember',\n",
       " 'men',\n",
       " 'women',\n",
       " 'south',\n",
       " 'side',\n",
       " 'chicago',\n",
       " 'stood',\n",
       " 'fought',\n",
       " 'two',\n",
       " 'decades',\n",
       " 'ago',\n",
       " 'local',\n",
       " 'steel',\n",
       " 'plant',\n",
       " 'closed',\n",
       " 'hear',\n",
       " 'woman',\n",
       " 'talk',\n",
       " 'difficulties',\n",
       " 'starting',\n",
       " 'business',\n",
       " 'think',\n",
       " 'grandmother',\n",
       " 'worked',\n",
       " 'way',\n",
       " 'secretarial',\n",
       " 'pool',\n",
       " 'middle',\n",
       " 'management',\n",
       " 'despite',\n",
       " 'years',\n",
       " 'passed',\n",
       " 'promotions',\n",
       " 'woman',\n",
       " 'one',\n",
       " 'taught',\n",
       " 'hard',\n",
       " 'work',\n",
       " 'one',\n",
       " 'put',\n",
       " 'buying',\n",
       " 'new',\n",
       " 'car',\n",
       " 'new',\n",
       " 'dress',\n",
       " 'could',\n",
       " 'better',\n",
       " 'life',\n",
       " 'poured',\n",
       " 'everything',\n",
       " 'although',\n",
       " 'longer',\n",
       " 'travel',\n",
       " 'know',\n",
       " 'watching',\n",
       " 'tonight',\n",
       " 'tonight',\n",
       " 'night',\n",
       " 'well',\n",
       " 'know',\n",
       " 'kind',\n",
       " 'lives',\n",
       " 'john',\n",
       " 'mccain',\n",
       " 'thinks',\n",
       " 'celebrities',\n",
       " 'lead',\n",
       " 'mine',\n",
       " 'heroes',\n",
       " 'stories',\n",
       " 'shaped',\n",
       " 'behalf',\n",
       " 'intend',\n",
       " 'win',\n",
       " 'election',\n",
       " 'keep',\n",
       " 'promise',\n",
       " 'alive',\n",
       " 'president',\n",
       " 'united',\n",
       " 'states',\n",
       " 'promise',\n",
       " 'promise',\n",
       " 'says',\n",
       " 'us',\n",
       " 'freedom',\n",
       " 'make',\n",
       " 'lives',\n",
       " 'also',\n",
       " 'obligation',\n",
       " 'treat',\n",
       " 'dignity',\n",
       " 'respect',\n",
       " 'promise',\n",
       " 'says',\n",
       " 'market',\n",
       " 'reward',\n",
       " 'drive',\n",
       " 'innovation',\n",
       " 'generate',\n",
       " 'growth',\n",
       " 'businesses',\n",
       " 'live',\n",
       " 'responsibilities',\n",
       " 'create',\n",
       " 'american',\n",
       " 'jobs',\n",
       " 'look',\n",
       " 'american',\n",
       " 'workers',\n",
       " 'play',\n",
       " 'rules',\n",
       " 'road',\n",
       " 'promise',\n",
       " 'says',\n",
       " 'government',\n",
       " 'solve',\n",
       " 'problems',\n",
       " 'protect',\n",
       " 'us',\n",
       " 'harm',\n",
       " 'provide',\n",
       " 'every',\n",
       " 'child',\n",
       " 'decent',\n",
       " 'education',\n",
       " 'keep',\n",
       " 'water',\n",
       " 'clean',\n",
       " 'toys',\n",
       " 'safe',\n",
       " 'invest',\n",
       " 'new',\n",
       " 'schools',\n",
       " 'new',\n",
       " 'roads',\n",
       " 'new',\n",
       " 'science',\n",
       " 'technology',\n",
       " 'government',\n",
       " 'work',\n",
       " 'us',\n",
       " 'us',\n",
       " 'help',\n",
       " 'us',\n",
       " 'hurt',\n",
       " 'us',\n",
       " 'ensure',\n",
       " 'opportunity',\n",
       " 'money',\n",
       " 'influence',\n",
       " 'every',\n",
       " 'american',\n",
       " 'willing',\n",
       " 'work',\n",
       " 'promise',\n",
       " 'america',\n",
       " 'idea',\n",
       " 'responsible',\n",
       " 'also',\n",
       " 'rise',\n",
       " 'fall',\n",
       " 'one',\n",
       " 'nation',\n",
       " 'fundamental',\n",
       " 'belief',\n",
       " 'brother',\n",
       " 'keeper',\n",
       " 'sister',\n",
       " 'keeper',\n",
       " 'promise',\n",
       " 'need',\n",
       " 'keep',\n",
       " 'change',\n",
       " 'need',\n",
       " 'right',\n",
       " 'let',\n",
       " 'spell',\n",
       " 'exactly',\n",
       " 'change',\n",
       " 'would',\n",
       " 'mean',\n",
       " 'president',\n",
       " 'change',\n",
       " 'means',\n",
       " 'tax',\n",
       " 'code',\n",
       " 'reward',\n",
       " 'lobbyists',\n",
       " 'wrote',\n",
       " 'american',\n",
       " 'workers',\n",
       " 'small',\n",
       " 'businesses',\n",
       " 'deserve',\n",
       " 'unlike',\n",
       " 'john',\n",
       " 'mccain',\n",
       " 'stop',\n",
       " 'giving',\n",
       " 'tax',\n",
       " 'breaks',\n",
       " 'corporations',\n",
       " 'ship',\n",
       " 'jobs',\n",
       " 'overseas',\n",
       " 'start',\n",
       " 'giving',\n",
       " 'companies',\n",
       " 'create',\n",
       " 'good',\n",
       " 'jobs',\n",
       " 'right',\n",
       " 'america',\n",
       " 'eliminate',\n",
       " 'capital',\n",
       " 'gains',\n",
       " 'taxes',\n",
       " 'small',\n",
       " 'businesses',\n",
       " 'start',\n",
       " 'ups',\n",
       " 'create',\n",
       " 'high',\n",
       " 'wage',\n",
       " 'high',\n",
       " 'tech',\n",
       " 'jobs',\n",
       " 'tomorrow',\n",
       " 'cut',\n",
       " 'taxes',\n",
       " 'cut',\n",
       " 'taxes',\n",
       " 'percent',\n",
       " 'working',\n",
       " 'families',\n",
       " 'economy',\n",
       " 'like',\n",
       " 'last',\n",
       " 'thing',\n",
       " 'raise',\n",
       " 'taxes',\n",
       " 'middle',\n",
       " 'class',\n",
       " 'sake',\n",
       " 'economy',\n",
       " 'security',\n",
       " 'future',\n",
       " 'planet',\n",
       " 'set',\n",
       " 'clear',\n",
       " 'goal',\n",
       " 'president',\n",
       " 'ten',\n",
       " 'years',\n",
       " 'finally',\n",
       " 'end',\n",
       " 'dependence',\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-pioneer",
   "metadata": {},
   "outputs": [],
   "source": [
    "obama_str = str(obama)\n",
    "word_tokens = word_tokenize(obama_str)\n",
    "tokens_without_sw = [w for w in word_tokens if not w in stop_words]\n",
    "#tokens_without_sw = []        \n",
    "obama_filtered = (\"\").join(tokens_without_sw)\n",
    "obama_filtered = obama_filtered.replace(' , ', '')\n",
    "obama_filtered = obama_filtered.replace(\" ''\", \"\")\n",
    "obama_filtered = obama_filtered.replace(\"''\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "renewable-business",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207326"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(obama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "institutional-pottery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103.663"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(obama)/2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-fruit",
   "metadata": {},
   "source": [
    "For ease of segmenting, I divided the length of the text by 2000 to get the amount of segments (1,101,169/2000 = ~550 Segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "obama1=[]\n",
    "for i in range(760):\n",
    "    obama1.append([obama_filtered[i*2000:(i+1)*2000], 'ob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "washington = [word.lower() for word in washington if word.isalpha()]\n",
    "washington_str = str(washington)\n",
    "word_tokens = word_tokenize(washington_str)\n",
    "tokens_without_sw = [w for w in word_tokens if not w in stop_words]\n",
    "#tokens_without_sw = []        \n",
    "washington_filtered = (\"\").join(tokens_without_sw)\n",
    "washington_filtered = washington_filtered.replace(' , ', '')\n",
    "washington_filtered = washington_filtered.replace(\" ''\", \"\")\n",
    "washington_filtered = washington_filtered.replace(\"''\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reagan_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-christmas",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(washington_filtered)/2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "washington1=[]\n",
    "for i in range(775):\n",
    "    washington1.append([washington_filtered[i*2000:(i+1)*2000], 're'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-sensitivity",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "Creating the list of 1000 most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "wo = obama+washington\n",
    "all_words = nltk.FreqDist(w.lower() for w in wo)\n",
    "word_features = list(all_words)[:1000] #1000 most frequent words\n",
    "wlist=[]\n",
    "for i in range(0,1000,50):\n",
    "    df=pd.DataFrame(word_features[i:(i+50)])\n",
    "    df.columns=['50 words']\n",
    "    wlist.append(df)   \n",
    "pd.concat(wlist, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-disney",
   "metadata": {},
   "source": [
    "From text book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-refund",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document): \n",
    "    document_words = set(document) \n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-render",
   "metadata": {},
   "source": [
    "run features on Washington's speeches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-puppy",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = document_features(washington)\n",
    "list(features.items())[10:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-touch",
   "metadata": {},
   "source": [
    "## Test/Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = obama1+washington1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(speeches)\n",
    "featuresets = [(document_features(d), c) for (d,c) in speeches]\n",
    "len(featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-listening",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = featuresets[:1000], featuresets[1000:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-genre",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-radiation",
   "metadata": {},
   "source": [
    "92%, the concept works!\n",
    "\n",
    "Does it get better or worse if we focus on speakers all from the same general era?."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-overview",
   "metadata": {},
   "source": [
    "### Adding Roosevelt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-folder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro=open('data/roosevelt.txt','rU')\n",
    "raw_r=ro.read()\n",
    "tokens_r = nltk.word_tokenize(raw_r)\n",
    "roosevelt = nltk.Text(tokens_r)\n",
    "roosevelt = [word.lower() for word in roosevelt if word.isalpha()]\n",
    "roosevelt_str = str(roosevelt)\n",
    "word_tokens = word_tokenize(roosevelt_str)\n",
    "tokens_without_sw = [w for w in word_tokens if not w in stop_words]\n",
    "#tokens_without_sw = []        \n",
    "roosevelt_filtered = (\" \").join(tokens_without_sw)\n",
    "roosevelt_filtered = roosevelt_filtered.replace(' , ', '')\n",
    "roosevelt_filtered = roosevelt_filtered.replace(\" ''\", \" \")\n",
    "\n",
    "len(roosevelt_filtered)/2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-steps",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "roosevelt1=[]\n",
    "for i in range(365):\n",
    "    roosevelt1.append([roosevelt_filtered[i*2000:(i+1)*2000], 'ro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro = obama+roosevelt\n",
    "all_words = nltk.FreqDist(w.lower() for w in ro)\n",
    "word_features = list(all_words)[:200] #200 most frequent words\n",
    "\n",
    "speeches = obama1+roosevelt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(speeches)\n",
    "featuresets = [(document_features(d), c) for (d,c) in speeches]\n",
    "len(featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-property",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = featuresets[:100], featuresets[100:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set)) "
   ]
  },
  {
   "cell_type": "raw",
   "id": "nasty-galaxy",
   "metadata": {},
   "source": [
    "67% not bad when focused on two presidents.  Not as good as the Washington/Obama model but still workable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-mileage",
   "metadata": {},
   "source": [
    "## Kennedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-electricity",
   "metadata": {},
   "outputs": [],
   "source": [
    "ke=open('data/kennedy.txt','rU')\n",
    "raw_k=ke.read()\n",
    "tokens_k = nltk.word_tokenize(raw_k)\n",
    "kennedy = nltk.Text(tokens_k)\n",
    "kennedy = [word.lower() for word in kennedy if word.isalpha()]\n",
    "kennedy_str = str(kennedy)\n",
    "word_tokens = word_tokenize(kennedy_str)\n",
    "tokens_without_sw = [w for w in word_tokens if not w in stop_words]\n",
    "#tokens_without_sw = []        \n",
    "kennedy_filtered = (\" \").join(tokens_without_sw)\n",
    "kennedy_filtered = kennedy_filtered.replace(' , ', '')\n",
    "kennedy_filtered = kennedy_filtered.replace(\" ''\", \" \")\n",
    "\n",
    "len(kennedy_filtered)/2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-sucking",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-amber",
   "metadata": {},
   "outputs": [],
   "source": [
    "kennedy1=[]\n",
    "for i in range(336):\n",
    "    kennedy1.append([kennedy_filtered[i*2000:(i+1)*2000], 'ke'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "ork = obama+roosevelt+kennedy\n",
    "all_words = nltk.FreqDist(w.lower() for w in ork)\n",
    "word_features = list(all_words)[:200] #200 most frequent words\n",
    "\n",
    "speeches = obama1+roosevelt1+kennedy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-sampling",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(speeches)\n",
    "featuresets = [(document_features(d), c) for (d,c) in speeches]\n",
    "len(featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-cloud",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = featuresets[:100], featuresets[100:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-content",
   "metadata": {},
   "source": [
    "words words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-johnson",
   "metadata": {},
   "source": [
    "## Clinton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-strengthening",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl=open('data/clinton.txt','rU')\n",
    "raw_c=cl.read()\n",
    "tokens_c = nltk.word_tokenize(raw_c)\n",
    "clinton = nltk.Text(tokens_c)\n",
    "clinton = [word.lower() for word in clinton if word.isalpha()]\n",
    "clinton_str = str(clinton)\n",
    "word_tokens = word_tokenize(clinton_str)\n",
    "tokens_without_sw = [w for w in word_tokens if not w in stop_words]\n",
    "#tokens_without_sw = []        \n",
    "clinton_filtered = (\" \").join(tokens_without_sw)\n",
    "clinton_filtered = clinton_filtered.replace(' , ', '')\n",
    "clinton_filtered = clinton_filtered.replace(\" ''\", \" \")\n",
    "\n",
    "len(clinton_filtered)/2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-comedy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinton1=[]\n",
    "for i in range(367):\n",
    "    clinton1.append([clinton_filtered[i*2000:(i+1)*2000], 'cl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-brighton",
   "metadata": {},
   "outputs": [],
   "source": [
    "orkc = obama+roosevelt+kennedy+clinton\n",
    "all_words = nltk.FreqDist(w.lower() for w in orkc)\n",
    "word_features = list(all_words)[:200] #200 most frequent words\n",
    "\n",
    "speeches = obama1+roosevelt1+kennedy1+clinton1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(speeches)\n",
    "featuresets = [(document_features(d), c) for (d,c) in speeches]\n",
    "len(featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-acrobat",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = featuresets[:100], featuresets[100:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-century",
   "metadata": {},
   "source": [
    "words words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-characteristic",
   "metadata": {},
   "source": [
    "## Reagan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-margin",
   "metadata": {},
   "outputs": [],
   "source": [
    "re=open('data/reagan.txt','rU')\n",
    "raw_re=re.read()\n",
    "tokens_re = nltk.word_tokenize(raw_re)\n",
    "reagan = nltk.Text(tokens_re)\n",
    "reagan = [word.lower() for word in reagan if word.isalpha()]\n",
    "reagan_str = str(reagan)\n",
    "word_tokens = word_tokenize(reagan_str)\n",
    "tokens_without_sw = [w for w in word_tokens if not w in stop_words]\n",
    "#tokens_without_sw = []        \n",
    "reagan_filtered = (\" \").join(tokens_without_sw)\n",
    "reagan_filtered = reagan_filtered.replace(' , ', '')\n",
    "reagan_filtered = reagan_filtered.replace(\" ''\", \" \")\n",
    "\n",
    "len(reagan_filtered)/2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "reagan1=[]\n",
    "for i in range(564):\n",
    "    reagan1.append([reagan_filtered[i*2000:(i+1)*2000], 'cl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-donna",
   "metadata": {},
   "outputs": [],
   "source": [
    "orkcr = obama+roosevelt+kennedy+clinton+reagan\n",
    "all_words = nltk.FreqDist(w.lower() for w in orkcr)\n",
    "word_features = list(all_words)[:200] #200 most frequent words\n",
    "\n",
    "speeches = obama1+roosevelt1+kennedy1+clinton1+reagan1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(speeches)\n",
    "featuresets = [(document_features(d), c) for (d,c) in speeches]\n",
    "len(featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = featuresets[:100], featuresets[100:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-taxation",
   "metadata": {},
   "source": [
    "38% proves our initial concern.  Since we are basing this research on speeches of people all from near the same era, it can be extremely difficult to teach a model to predict as more and more text gets added.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-wiring",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-preliminary",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
